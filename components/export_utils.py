"""
Export utilities for generating CSV, Excel, PDF, and ZIP exports with role-based access control.
"""
import os
import json
import logging
import zipfile
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Optional, Union
import pandas as pd
from fpdf import FPDF
from io import BytesIO
import tempfile
import shutil

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Base export directory (will be set during app initialization)
BASE_EXPORT_DIR = None

# Role-based column masks
COLUMN_MASKS = {
    'admin': [],  # Admins see all columns
    'user': ['ssn', 'salary', 'internal_notes', 'sensitive_data'],
    'viewer': ['ssn', 'salary', 'internal_notes', 'sensitive_data', 'contact_info']
}


def set_export_dir(export_dir: str) -> None:
    """Set the base export directory and ensure it exists."""
    global BASE_EXPORT_DIR
    BASE_EXPORT_DIR = Path(export_dir)
    os.makedirs(BASE_EXPORT_DIR, exist_ok=True)


def get_user_export_dir(user_id: str) -> Path:
    """Get or create a user-specific export directory."""
    if not BASE_EXPORT_DIR:
        raise ValueError("Export directory not set. Call set_export_dir() first.")
    
    user_dir = BASE_EXPORT_DIR / str(user_id)
    user_dir.mkdir(parents=True, exist_ok=True)
    return user_dir


def mask_sensitive_columns(df: pd.DataFrame, role: str) -> pd.DataFrame:
    """Remove or mask sensitive columns based on user role."""
    if role not in COLUMN_MASKS:
        role = 'viewer'  # Default to most restrictive
    
    columns_to_drop = [col for col in COLUMN_MASKS[role] if col in df.columns]
    if columns_to_drop:
        logger.info(f"Masking columns for role '{role}': {columns_to_drop}")
        return df.drop(columns=columns_to_drop)
    return df


def generate_filename(base_name: str, extension: str) -> str:
    """Generate a unique filename with timestamp."""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    return f"{base_name}_{timestamp}.{extension}"


def export_to_csv(df: pd.DataFrame, user_id: str, base_name: str = "export") -> str:
    """Export DataFrame to CSV file."""
    user_dir = get_user_export_dir(user_id)
    filename = generate_filename(base_name, "csv")
    filepath = user_dir / filename
    
    df.to_csv(filepath, index=False)
    return str(filepath)


def export_to_excel(df: pd.DataFrame, user_id: str, base_name: str = "export") -> str:
    """Export DataFrame to Excel file."""
    user_dir = get_user_export_dir(user_id)
    filename = generate_filename(base_name, "xlsx")
    filepath = user_dir / filename
    
    with pd.ExcelWriter(filepath, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='Data')
        
        # Auto-adjust column widths
        worksheet = writer.sheets['Data']
        for idx, col in enumerate(df.columns):
            max_length = max(df[col].astype(str).apply(len).max(), len(col)) + 2
            worksheet.column_dimensions[chr(65 + idx)].width = min(max_length, 50)
    
    return str(filepath)


def export_to_pdf(df: pd.DataFrame, user_id: str, base_name: str = "export", 
                 title: str = "Export Report") -> str:
    """Export DataFrame to PDF with formatting and watermark."""
    user_dir = get_user_export_dir(user_id)
    filename = generate_filename(base_name, "pdf")
    filepath = user_dir / filename
    
    # Create PDF
    pdf = FPDF()
    pdf.add_page()
    
    # Add header
    pdf.set_font('Arial', 'B', 16)
    pdf.cell(0, 10, title, 0, 1, 'C')
    pdf.ln(10)
    
    # Add metadata
    pdf.set_font('Arial', '', 10)
    pdf.cell(0, 10, f"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", 0, 1)
    pdf.cell(0, 10, f"Total Records: {len(df)}", 0, 1)
    pdf.ln(10)
    
    # Add table headers
    col_widths = [min(max(df[col].astype(str).apply(len).max(), len(col)) * 2 + 2, 40) 
                 for col in df.columns]
    
    pdf.set_font('Arial', 'B', 10)
    for i, col in enumerate(df.columns):
        pdf.cell(col_widths[i], 10, str(col), 1, 0, 'C')
    pdf.ln()
    
    # Add table rows
    pdf.set_font('Arial', '', 8)
    for _, row in df.iterrows():
        for i, col in enumerate(df.columns):
            pdf.cell(col_widths[i], 6, str(row[col])[:30] + ('...' if len(str(row[col])) > 30 else ''), 1, 0, 'L')
        pdf.ln()
    
    # Add footer/watermark
    pdf.set_y(-15)
    pdf.set_font('Arial', 'I', 8)
    pdf.cell(0, 10, f'Generated by user: {user_id}', 0, 0, 'C')
    
    pdf.output(str(filepath))
    return str(filepath)


def create_zip_archive(file_paths: List[str], user_id: str, base_name: str = "export") -> str:
    """Create a ZIP archive containing multiple files."""
    if not file_paths:
        raise ValueError("No files provided to create ZIP archive")
    
    user_dir = get_user_export_dir(user_id)
    zip_filename = generate_filename(base_name, "zip")
    zip_path = user_dir / zip_filename
    
    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
        for file_path in file_paths:
            if Path(file_path).exists():
                zipf.write(file_path, arcname=Path(file_path).name)
    
    return str(zip_path)


def cleanup_old_exports(days: int = 30) -> None:
    """Remove export files older than specified days."""
    if not BASE_EXPORT_DIR:
        return
    
    cutoff_time = datetime.now().timestamp() - (days * 86400)
    
    for user_dir in BASE_EXPORT_DIR.iterdir():
        if user_dir.is_dir():
            for file_path in user_dir.glob('*.*'):
                if file_path.stat().st_mtime < cutoff_time:
                    try:
                        file_path.unlink()
                        logger.info(f"Removed old export file: {file_path}")
                    except Exception as e:
                        logger.error(f"Error removing {file_path}: {e}")
